{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KDTree\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(T, p):\n",
    "    random.shuffle(T)\n",
    "    return [T[i::p] for i in range(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict(data, x, k):\n",
    "    \n",
    "    # Convertir l'ensemble d'apprentissage en un tableau numpy pour les caractéristiques et les étiquettes\n",
    "    X_train = np.array([x for x, _ in data])\n",
    "    y_train = np.array([y for _, y in data])\n",
    "    \n",
    "    # Créer un KDTree à partir de l'ensemble d'apprentissage\n",
    "    tree = KDTree(X_train)\n",
    "    \n",
    "    # Trouver les indices des k voisins les plus proches\n",
    "    dists, indices = tree.query([x], k=k)\n",
    "    \n",
    "    # Obtenir les étiquettes des k voisins les plus proches\n",
    "    k_nearest_labels = y_train[indices[0]]\n",
    "    \n",
    "    # Retourner l'étiquette la plus commune parmi les k voisins\n",
    "    return Counter(k_nearest_labels).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNLearnInit(T, p):\n",
    "    # Partitionner l'ensemble d'apprentissage T en p groupes (G1, G2, ..., Gp)\n",
    "    groups = partition(T, p)\n",
    "    \n",
    "    candidate_values = [1, 2, 4, 6]\n",
    "    \n",
    "    errors = {Ki: [0 for _ in range(p)] for Ki in candidate_values}\n",
    "    \n",
    "    errSet = [[[] for _ in range(p)] for _ in candidate_values]\n",
    "    \n",
    "    for Ki in candidate_values:\n",
    "        # Calculer i la position de Ki dans candidate_values\n",
    "        i = candidate_values.index(Ki)\n",
    "        \n",
    "        for j, Gj in enumerate(groups):\n",
    "            for x, y in Gj:\n",
    "                data = [x for x in T if not any(np.array_equal(x[0], element[0]) and x[1] == element[1] for element in Gj)]\n",
    "                if knn_predict(data, x, Ki) != y:\n",
    "                    errSet[i][j].append((x,y))\n",
    "            errors[Ki][j] = len(errSet[i][j]) / len(Gj)\n",
    "            \n",
    "        \n",
    "        errors[Ki] = sum([errors[Ki][j] for j in range(p)]) / p\n",
    "    \n",
    "    # Obtenir Ki avec l'erreur minimale\n",
    "    K_star = min(errors, key=errors.get)\n",
    "    \n",
    "    Error_star = [(groups[j], errSet[candidate_values.index(K_star)][j]) for j in range(p)]\n",
    "    \n",
    "    return K_star, Error_star\n",
    "\n",
    "\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# # Créer une liste de paires (x, y) à partir de X et y\n",
    "xy = list(zip(X, y))\n",
    "\n",
    "print(KNNLearnInit(xy, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
