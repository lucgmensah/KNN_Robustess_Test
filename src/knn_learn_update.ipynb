{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict(training_data, k, test_instance):\n",
    "    \"\"\"\n",
    "    Prédit la classe d'une instance de test en fonction des k plus proches voisins.\n",
    "\n",
    "    :param training_data: Ensemble de données d'entraînement avec des paires (features, label).\n",
    "    :param k: Le nombre de voisins à considérer.\n",
    "    :param test_instance: L'instance à classer.\n",
    "    :return: La classe prédite pour l'instance de test.\n",
    "    \"\"\"\n",
    "    # Extract features from training data\n",
    "    features = [features for features, _ in training_data]\n",
    "\n",
    "    # Build KDTree from training data features\n",
    "    kdtree = KDTree(features)\n",
    "\n",
    "    # Query KDTree to find k nearest neighbors\n",
    "    _, indices = kdtree.query(test_instance, k=k)\n",
    "\n",
    "    # Get labels of k nearest neighbors\n",
    "    nearest_labels = [training_data[i][1] for i in indices]\n",
    "\n",
    "    # Find the most common label among the neighbors\n",
    "    most_common_label = Counter(nearest_labels).most_common(1)[0][0]\n",
    "\n",
    "    return most_common_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inflSet(R, groups):\n",
    "    \"\"\"\n",
    "    Calcule l'ensemble des points influencés par R.\n",
    "\n",
    "    :param R: Ensemble des points à supprimer.\n",
    "    :param groups: Les groupes actuels de points de données.\n",
    "    :return: Un ensemble de points influencés par R.\n",
    "    \"\"\"\n",
    "    # Pour simplifier, disons que tous les points sont influencés par R.\n",
    "    # Dans une implémentation réelle, vous devrez vérifier si la suppression\n",
    "    # de points dans R affecte les voisins les plus proches des points dans groups.\n",
    "    return set(itertools.chain.from_iterable(groups)) - set(R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(errSetGj_Ki, R, newSet_minus, newSet_plus):\n",
    "\n",
    "    # Retirer les indices R et newSet_minus de errSetGj_Ki\n",
    "    result = np.setdiff1d(errSetGj_Ki, R)\n",
    "    result = np.setdiff1d(errSetGj_Ki, newSet_minus)\n",
    "\n",
    "    # Ajouter les indices de newSet_plus à errSetGj_Ki\n",
    "    result = np.union1d(errSetGj_Ki, newSet_plus)\n",
    "\n",
    "    # Le tableau errSetGj_Ki est maintenant mis à jour\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNLearnUpdate(R, Error, candidate_k_values):\n",
    "    \"\"\"\n",
    "    Mise à jour incrémentielle du modèle KNN.\n",
    "\n",
    "    :param R: Ensemble des éléments à supprimer de l'entraînement.\n",
    "    :param Error: Contient des groupes et des ensembles d'erreurs.\n",
    "    :param candidate_k_values: Les valeurs k candidates pour le KNN.\n",
    "    :return: Le meilleur k basé sur la plus petite erreur.\n",
    "    \"\"\"\n",
    "    # Récupération des groupes et des ensembles d'erreurs\n",
    "    groups = []\n",
    "    err_sets = []\n",
    "    for elt in Error:\n",
    "        groups.append(elt[0])\n",
    "        err_sets.append(elt[1])\n",
    "\n",
    "    # Calcul des nouveaux groupes en supprimant R\n",
    "    new_groups = []\n",
    "    for elt in groups:\n",
    "        ensemble = [x for x in elt if not any(np.array_equal(x[0], element[0]) and x[1] == element[1] for element in R)]\n",
    "        new_groups.append(ensemble)\n",
    "\n",
    "    # Création du nouvel ensemble d'entraînement T'\n",
    "    T_prime = set().union(*new_groups)\n",
    "\n",
    "    # Initialisation de l'ensemble influencé par R\n",
    "    inflSet = compute_inflSet(R, groups)  # Cette fonction doit être définie\n",
    "\n",
    "    # Initialisation du dictionnaire pour les erreurs de chaque valeur k\n",
    "    error_prime = []\n",
    "    \n",
    "    err_sets_prime = []\n",
    "    \n",
    "    errors_for_k = []\n",
    "\n",
    "    # Itération sur chaque valeur k candidate\n",
    "    for k in candidate_k_values:\n",
    "        i = candidate_k_values.index(k)\n",
    "        # Itération sur chaque groupe\n",
    "        for j, Gj_prime in enumerate(new_groups):\n",
    "            newSet_minus = []\n",
    "            newSet_plus = []\n",
    "            # Itération sur chaque élément de données dans le groupe influencé\n",
    "            interGj_prime_inflSet = [x for x in Gj_prime if any(np.array_equal(x[0], element[0]) and x[1] == element[1] for element in inflSet)]\n",
    "            for x, y in interGj_prime_inflSet:\n",
    "                # Prédiction sur l'ensemble d'entraînement original\n",
    "                data = [x for x in T if not any(np.array_equal(x[0], element[0]) and x[1] == element[1] for element in Gj)]\n",
    "                data_prime = [x for x in T_prime if not any(np.array_equal(x[0], element[0]) and x[1] == element[1] for element in Gj_prime)]\n",
    "                if knn_predict(data, k, x) == y and knn_predict(data_prime, k, x) != y:\n",
    "                    newSet_plus.add((x, y))\n",
    "\n",
    "                if knn_predict(data, k, x) != y and knn_predict(data_prime, k, x) == y:\n",
    "                    newSet_minus.add((x, y))\n",
    "\n",
    "            # Mise à jour de l'ensemble des erreurs pour le groupe j\n",
    "            err_sets_prime[i][j] = ensemble(err_sets[j], R, newSet_minus, newSet_plus)\n",
    "            error_prime[i][j] = len(err_sets[Gj_prime]) / len(Gj_prime)\n",
    "\n",
    "        # Calcul de l'erreur moyenne pour la valeur k\n",
    "        avg_error_k = sum([error_prime[i][j] for j in range(len(groups))]) / len(groups))\n",
    "        errors_for_k[i] = avg_error_k\n",
    "\n",
    "    # Trouver le meilleur k avec la plus petite erreur moyenne\n",
    "    best_k = min(errors_for_k, key=errors_for_k.get)\n",
    "\n",
    "    return best_k"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
